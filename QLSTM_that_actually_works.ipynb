{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jkLm5i2BNI6i"
      },
      "source": [
        "# A Quantum-Enhanced LSTM Layer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6ZHZT8O4NI6k"
      },
      "source": [
        "One field that so far has been poorly explored in Quantum Machine Learning is Natural Language Processing (NLP), the sub-field of Artificial Intelligence that gives computers the ability to read, write and to some extent comprehend written text. \n",
        "\n",
        "As documents are usually presented as sequences of words, historically one of the most successful techniques to manipulate this kind of data has been the Recurrent Neural Network architecture, and in particular a variant called Long Short-Term Memory (LSTM). LSTMs allowed machines to perform translations, classification and intent detection with state-of-the-art accuracy until the advent of Transformer networks. Still, it’s interesting at least from an educational point of view to dig into LSTMs to see what good quantum computing may bring to the field. For a more thorough discussion, please refer to “Quantum Long Short-Term Memory” by Chen, Yoo and Fang (arXiv:2009.01783) and “Recurrent Quantum Neural Networks” by J. Bausch (arXiv:2006.14619)."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/rdisipio/qlstm/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J-dimaS7NkqN",
        "outputId": "093c4a77-8c16-46e7-8c17-3dac3547e313"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'qlstm'...\n",
            "remote: Enumerating objects: 117, done.\u001b[K\n",
            "remote: Counting objects: 100% (117/117), done.\u001b[K\n",
            "remote: Compressing objects: 100% (86/86), done.\u001b[K\n",
            "remote: Total 117 (delta 61), reused 80 (delta 27), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (117/117), 276.23 KiB | 16.25 MiB/s, done.\n",
            "Resolving deltas: 100% (61/61), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd qlstm"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E9EAsSQrNvps",
        "outputId": "1e9537da-c49e-4b58-f622-c47aff507dd2"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/qlstm\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "id": "5FhzTfGFNI6l",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2041803c-b70f-424e-cc51-2af006d1864e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: absl-py==0.12.0 in /usr/local/lib/python3.8/dist-packages (from -r requirements.txt (line 1)) (0.12.0)\n",
            "Requirement already satisfied: aiohttp==3.7.4.post0 in /usr/local/lib/python3.8/dist-packages (from -r requirements.txt (line 2)) (3.7.4.post0)\n",
            "Requirement already satisfied: appdirs==1.4.4 in /usr/local/lib/python3.8/dist-packages (from -r requirements.txt (line 3)) (1.4.4)\n",
            "Requirement already satisfied: appnope==0.1.2 in /usr/local/lib/python3.8/dist-packages (from -r requirements.txt (line 4)) (0.1.2)\n",
            "Requirement already satisfied: argon2-cffi==21.1.0 in /usr/local/lib/python3.8/dist-packages (from -r requirements.txt (line 5)) (21.1.0)\n",
            "Requirement already satisfied: async-timeout==3.0.1 in /usr/local/lib/python3.8/dist-packages (from -r requirements.txt (line 6)) (3.0.1)\n",
            "Requirement already satisfied: attrs==20.3.0 in /usr/local/lib/python3.8/dist-packages (from -r requirements.txt (line 7)) (20.3.0)\n",
            "Requirement already satisfied: autograd==1.3 in /usr/local/lib/python3.8/dist-packages (from -r requirements.txt (line 8)) (1.3)\n",
            "Requirement already satisfied: backcall==0.2.0 in /usr/local/lib/python3.8/dist-packages (from -r requirements.txt (line 9)) (0.2.0)\n",
            "Requirement already satisfied: beautifulsoup4==4.9.3 in /usr/local/lib/python3.8/dist-packages (from -r requirements.txt (line 10)) (4.9.3)\n",
            "Requirement already satisfied: bleach==4.1.0 in /usr/local/lib/python3.8/dist-packages (from -r requirements.txt (line 11)) (4.1.0)\n",
            "Requirement already satisfied: bs4==0.0.1 in /usr/local/lib/python3.8/dist-packages (from -r requirements.txt (line 12)) (0.0.1)\n",
            "Requirement already satisfied: cachetools==4.2.1 in /usr/local/lib/python3.8/dist-packages (from -r requirements.txt (line 13)) (4.2.1)\n",
            "Requirement already satisfied: certifi==2020.12.5 in /usr/local/lib/python3.8/dist-packages (from -r requirements.txt (line 14)) (2020.12.5)\n",
            "Requirement already satisfied: cffi==1.14.5 in /usr/local/lib/python3.8/dist-packages (from -r requirements.txt (line 15)) (1.14.5)\n",
            "Requirement already satisfied: chardet==4.0.0 in /usr/local/lib/python3.8/dist-packages (from -r requirements.txt (line 16)) (4.0.0)\n",
            "Requirement already satisfied: click==7.1.2 in /usr/local/lib/python3.8/dist-packages (from -r requirements.txt (line 17)) (7.1.2)\n",
            "Requirement already satisfied: cryptography==3.4.7 in /usr/local/lib/python3.8/dist-packages (from -r requirements.txt (line 18)) (3.4.7)\n",
            "Requirement already satisfied: cycler==0.10.0 in /usr/local/lib/python3.8/dist-packages (from -r requirements.txt (line 19)) (0.10.0)\n",
            "Requirement already satisfied: debugpy==1.4.3 in /usr/local/lib/python3.8/dist-packages (from -r requirements.txt (line 20)) (1.4.3)\n",
            "Requirement already satisfied: decorator==4.4.2 in /usr/local/lib/python3.8/dist-packages (from -r requirements.txt (line 21)) (4.4.2)\n",
            "Requirement already satisfied: defusedxml==0.7.1 in /usr/local/lib/python3.8/dist-packages (from -r requirements.txt (line 22)) (0.7.1)\n",
            "Requirement already satisfied: dill==0.3.3 in /usr/local/lib/python3.8/dist-packages (from -r requirements.txt (line 23)) (0.3.3)\n",
            "Requirement already satisfied: dlx==1.0.4 in /usr/local/lib/python3.8/dist-packages (from -r requirements.txt (line 24)) (1.0.4)\n",
            "Requirement already satisfied: docplex==2.15.194 in /usr/local/lib/python3.8/dist-packages (from -r requirements.txt (line 25)) (2.15.194)\n",
            "Requirement already satisfied: entrypoints==0.3 in /usr/local/lib/python3.8/dist-packages (from -r requirements.txt (line 26)) (0.3)\n",
            "Requirement already satisfied: fastdtw==0.3.4 in /usr/local/lib/python3.8/dist-packages (from -r requirements.txt (line 27)) (0.3.4)\n",
            "Requirement already satisfied: fastjsonschema==2.15.0 in /usr/local/lib/python3.8/dist-packages (from -r requirements.txt (line 28)) (2.15.0)\n",
            "Requirement already satisfied: fsspec==0.9.0 in /usr/local/lib/python3.8/dist-packages (from -r requirements.txt (line 29)) (0.9.0)\n",
            "Requirement already satisfied: future==0.18.2 in /usr/local/lib/python3.8/dist-packages (from -r requirements.txt (line 30)) (0.18.2)\n",
            "Requirement already satisfied: google-auth==1.28.0 in /usr/local/lib/python3.8/dist-packages (from -r requirements.txt (line 31)) (1.28.0)\n",
            "Requirement already satisfied: google-auth-oauthlib==0.4.4 in /usr/local/lib/python3.8/dist-packages (from -r requirements.txt (line 32)) (0.4.4)\n",
            "Requirement already satisfied: grpcio==1.37.0 in /usr/local/lib/python3.8/dist-packages (from -r requirements.txt (line 33)) (1.37.0)\n",
            "Requirement already satisfied: h5py==3.1.0 in /usr/local/lib/python3.8/dist-packages (from -r requirements.txt (line 34)) (3.1.0)\n",
            "Requirement already satisfied: idna==2.10 in /usr/local/lib/python3.8/dist-packages (from -r requirements.txt (line 35)) (2.10)\n",
            "Requirement already satisfied: inflection==0.5.1 in /usr/local/lib/python3.8/dist-packages (from -r requirements.txt (line 36)) (0.5.1)\n",
            "Requirement already satisfied: ipykernel==6.4.1 in /usr/local/lib/python3.8/dist-packages (from -r requirements.txt (line 37)) (6.4.1)\n",
            "Requirement already satisfied: ipython==7.28.0 in /usr/local/lib/python3.8/dist-packages (from -r requirements.txt (line 38)) (7.28.0)\n",
            "Requirement already satisfied: ipython-genutils==0.2.0 in /usr/local/lib/python3.8/dist-packages (from -r requirements.txt (line 39)) (0.2.0)\n",
            "Requirement already satisfied: ipywidgets==7.6.5 in /usr/local/lib/python3.8/dist-packages (from -r requirements.txt (line 40)) (7.6.5)\n",
            "Requirement already satisfied: jedi==0.18.0 in /usr/local/lib/python3.8/dist-packages (from -r requirements.txt (line 41)) (0.18.0)\n",
            "Requirement already satisfied: Jinja2==3.0.1 in /usr/local/lib/python3.8/dist-packages (from -r requirements.txt (line 42)) (3.0.1)\n",
            "Requirement already satisfied: joblib==1.0.1 in /usr/local/lib/python3.8/dist-packages (from -r requirements.txt (line 43)) (1.0.1)\n",
            "Requirement already satisfied: jsonschema==3.2.0 in /usr/local/lib/python3.8/dist-packages (from -r requirements.txt (line 44)) (3.2.0)\n",
            "Requirement already satisfied: jupyter==1.0.0 in /usr/local/lib/python3.8/dist-packages (from -r requirements.txt (line 45)) (1.0.0)\n",
            "Requirement already satisfied: jupyter-client==7.0.5 in /usr/local/lib/python3.8/dist-packages (from -r requirements.txt (line 46)) (7.0.5)\n",
            "Requirement already satisfied: jupyter-console==6.4.0 in /usr/local/lib/python3.8/dist-packages (from -r requirements.txt (line 47)) (6.4.0)\n",
            "Requirement already satisfied: jupyter-core==4.8.1 in /usr/local/lib/python3.8/dist-packages (from -r requirements.txt (line 48)) (4.8.1)\n",
            "Requirement already satisfied: jupyterlab-pygments==0.1.2 in /usr/local/lib/python3.8/dist-packages (from -r requirements.txt (line 49)) (0.1.2)\n",
            "Requirement already satisfied: jupyterlab-widgets==1.0.2 in /usr/local/lib/python3.8/dist-packages (from -r requirements.txt (line 50)) (1.0.2)\n",
            "Requirement already satisfied: kiwisolver==1.3.1 in /usr/local/lib/python3.8/dist-packages (from -r requirements.txt (line 51)) (1.3.1)\n",
            "Requirement already satisfied: lxml==4.6.3 in /usr/local/lib/python3.8/dist-packages (from -r requirements.txt (line 52)) (4.6.3)\n",
            "Requirement already satisfied: Markdown==3.3.4 in /usr/local/lib/python3.8/dist-packages (from -r requirements.txt (line 53)) (3.3.4)\n",
            "Requirement already satisfied: MarkupSafe==2.0.1 in /usr/local/lib/python3.8/dist-packages (from -r requirements.txt (line 54)) (2.0.1)\n",
            "Collecting matplotlib==3.4.1\n",
            "  Using cached matplotlib-3.4.1-cp38-cp38-manylinux1_x86_64.whl (10.3 MB)\n",
            "Requirement already satisfied: matplotlib-inline==0.1.3 in /usr/local/lib/python3.8/dist-packages (from -r requirements.txt (line 56)) (0.1.3)\n",
            "Requirement already satisfied: mistune==0.8.4 in /usr/local/lib/python3.8/dist-packages (from -r requirements.txt (line 57)) (0.8.4)\n",
            "Requirement already satisfied: more-itertools==8.7.0 in /usr/local/lib/python3.8/dist-packages (from -r requirements.txt (line 58)) (8.7.0)\n",
            "Requirement already satisfied: mpmath==1.2.1 in /usr/local/lib/python3.8/dist-packages (from -r requirements.txt (line 59)) (1.2.1)\n",
            "Requirement already satisfied: multidict==5.1.0 in /usr/local/lib/python3.8/dist-packages (from -r requirements.txt (line 60)) (5.1.0)\n",
            "Requirement already satisfied: multitasking==0.0.9 in /usr/local/lib/python3.8/dist-packages (from -r requirements.txt (line 61)) (0.0.9)\n",
            "Requirement already satisfied: nbclient==0.5.4 in /usr/local/lib/python3.8/dist-packages (from -r requirements.txt (line 62)) (0.5.4)\n",
            "Requirement already satisfied: nbconvert==6.2.0 in /usr/local/lib/python3.8/dist-packages (from -r requirements.txt (line 63)) (6.2.0)\n",
            "Requirement already satisfied: nbformat==5.1.3 in /usr/local/lib/python3.8/dist-packages (from -r requirements.txt (line 64)) (5.1.3)\n",
            "Requirement already satisfied: nest-asyncio==1.5.1 in /usr/local/lib/python3.8/dist-packages (from -r requirements.txt (line 65)) (1.5.1)\n",
            "Requirement already satisfied: networkx==2.5.1 in /usr/local/lib/python3.8/dist-packages (from -r requirements.txt (line 66)) (2.5.1)\n",
            "Requirement already satisfied: nltk==3.6.1 in /usr/local/lib/python3.8/dist-packages (from -r requirements.txt (line 67)) (3.6.1)\n",
            "Requirement already satisfied: notebook==6.4.4 in /usr/local/lib/python3.8/dist-packages (from -r requirements.txt (line 68)) (6.4.4)\n",
            "Requirement already satisfied: ntlm-auth==1.5.0 in /usr/local/lib/python3.8/dist-packages (from -r requirements.txt (line 69)) (1.5.0)\n",
            "Requirement already satisfied: numpy==1.20.1 in /usr/local/lib/python3.8/dist-packages (from -r requirements.txt (line 70)) (1.20.1)\n",
            "Requirement already satisfied: oauthlib==3.1.0 in /usr/local/lib/python3.8/dist-packages (from -r requirements.txt (line 71)) (3.1.0)\n",
            "Requirement already satisfied: packaging==21.0 in /usr/local/lib/python3.8/dist-packages (from -r requirements.txt (line 72)) (21.0)\n",
            "Requirement already satisfied: pandas==1.2.3 in /usr/local/lib/python3.8/dist-packages (from -r requirements.txt (line 73)) (1.2.3)\n",
            "Requirement already satisfied: pandocfilters==1.5.0 in /usr/local/lib/python3.8/dist-packages (from -r requirements.txt (line 74)) (1.5.0)\n",
            "Requirement already satisfied: parso==0.8.2 in /usr/local/lib/python3.8/dist-packages (from -r requirements.txt (line 75)) (0.8.2)\n",
            "Requirement already satisfied: PennyLane==0.14.1 in /usr/local/lib/python3.8/dist-packages (from -r requirements.txt (line 76)) (0.14.1)\n",
            "Requirement already satisfied: PennyLane-qiskit==0.14.0 in /usr/local/lib/python3.8/dist-packages (from -r requirements.txt (line 77)) (0.14.0)\n",
            "Requirement already satisfied: pexpect==4.8.0 in /usr/local/lib/python3.8/dist-packages (from -r requirements.txt (line 78)) (4.8.0)\n",
            "Requirement already satisfied: pickleshare==0.7.5 in /usr/local/lib/python3.8/dist-packages (from -r requirements.txt (line 79)) (0.7.5)\n",
            "Requirement already satisfied: Pillow==8.2.0 in /usr/local/lib/python3.8/dist-packages (from -r requirements.txt (line 80)) (8.2.0)\n",
            "Requirement already satisfied: ply==3.11 in /usr/local/lib/python3.8/dist-packages (from -r requirements.txt (line 81)) (3.11)\n",
            "Requirement already satisfied: prometheus-client==0.11.0 in /usr/local/lib/python3.8/dist-packages (from -r requirements.txt (line 82)) (0.11.0)\n",
            "Requirement already satisfied: prompt-toolkit==3.0.20 in /usr/local/lib/python3.8/dist-packages (from -r requirements.txt (line 83)) (3.0.20)\n",
            "Requirement already satisfied: protobuf==3.15.7 in /usr/local/lib/python3.8/dist-packages (from -r requirements.txt (line 84)) (3.15.7)\n",
            "Requirement already satisfied: psutil==5.8.0 in /usr/local/lib/python3.8/dist-packages (from -r requirements.txt (line 85)) (5.8.0)\n",
            "Requirement already satisfied: ptyprocess==0.7.0 in /usr/local/lib/python3.8/dist-packages (from -r requirements.txt (line 86)) (0.7.0)\n",
            "Requirement already satisfied: pyasn1==0.4.8 in /usr/local/lib/python3.8/dist-packages (from -r requirements.txt (line 87)) (0.4.8)\n",
            "Requirement already satisfied: pyasn1-modules==0.2.8 in /usr/local/lib/python3.8/dist-packages (from -r requirements.txt (line 88)) (0.2.8)\n",
            "Requirement already satisfied: pybind11==2.6.2 in /usr/local/lib/python3.8/dist-packages (from -r requirements.txt (line 89)) (2.6.2)\n",
            "Requirement already satisfied: pycparser==2.20 in /usr/local/lib/python3.8/dist-packages (from -r requirements.txt (line 90)) (2.20)\n",
            "Requirement already satisfied: Pygments==2.10.0 in /usr/local/lib/python3.8/dist-packages (from -r requirements.txt (line 91)) (2.10.0)\n",
            "Requirement already satisfied: pyparsing==2.4.7 in /usr/local/lib/python3.8/dist-packages (from -r requirements.txt (line 92)) (2.4.7)\n",
            "Requirement already satisfied: pyrsistent==0.17.3 in /usr/local/lib/python3.8/dist-packages (from -r requirements.txt (line 93)) (0.17.3)\n",
            "Requirement already satisfied: python-constraint==1.4.0 in /usr/local/lib/python3.8/dist-packages (from -r requirements.txt (line 94)) (1.4.0)\n",
            "Requirement already satisfied: python-dateutil==2.8.1 in /usr/local/lib/python3.8/dist-packages (from -r requirements.txt (line 95)) (2.8.1)\n",
            "Requirement already satisfied: pytorch-lightning==1.2.7 in /usr/local/lib/python3.8/dist-packages (from -r requirements.txt (line 96)) (1.2.7)\n",
            "Requirement already satisfied: pytz==2021.1 in /usr/local/lib/python3.8/dist-packages (from -r requirements.txt (line 97)) (2021.1)\n",
            "Requirement already satisfied: PyYAML==5.3.1 in /usr/local/lib/python3.8/dist-packages (from -r requirements.txt (line 98)) (5.3.1)\n",
            "Requirement already satisfied: pyzmq==22.3.0 in /usr/local/lib/python3.8/dist-packages (from -r requirements.txt (line 99)) (22.3.0)\n",
            "Requirement already satisfied: qiskit==0.25.0 in /usr/local/lib/python3.8/dist-packages (from -r requirements.txt (line 100)) (0.25.0)\n",
            "Requirement already satisfied: qiskit-aer==0.8.0 in /usr/local/lib/python3.8/dist-packages (from -r requirements.txt (line 101)) (0.8.0)\n",
            "Requirement already satisfied: qiskit-aqua==0.9.0 in /usr/local/lib/python3.8/dist-packages (from -r requirements.txt (line 102)) (0.9.0)\n",
            "Requirement already satisfied: qiskit-ibmq-provider==0.12.2 in /usr/local/lib/python3.8/dist-packages (from -r requirements.txt (line 103)) (0.12.2)\n",
            "Requirement already satisfied: qiskit-ignis==0.6.0 in /usr/local/lib/python3.8/dist-packages (from -r requirements.txt (line 104)) (0.6.0)\n",
            "Requirement already satisfied: qiskit-terra==0.17.0 in /usr/local/lib/python3.8/dist-packages (from -r requirements.txt (line 105)) (0.17.0)\n",
            "Requirement already satisfied: qtconsole==5.1.1 in /usr/local/lib/python3.8/dist-packages (from -r requirements.txt (line 106)) (5.1.1)\n",
            "Requirement already satisfied: QtPy==1.11.2 in /usr/local/lib/python3.8/dist-packages (from -r requirements.txt (line 107)) (1.11.2)\n",
            "Requirement already satisfied: Quandl==3.6.0 in /usr/local/lib/python3.8/dist-packages (from -r requirements.txt (line 108)) (3.6.0)\n",
            "Requirement already satisfied: regex==2021.4.4 in /usr/local/lib/python3.8/dist-packages (from -r requirements.txt (line 109)) (2021.4.4)\n",
            "Requirement already satisfied: requests==2.25.1 in /usr/local/lib/python3.8/dist-packages (from -r requirements.txt (line 110)) (2.25.1)\n",
            "Requirement already satisfied: requests-ntlm==1.1.0 in /usr/local/lib/python3.8/dist-packages (from -r requirements.txt (line 111)) (1.1.0)\n",
            "Requirement already satisfied: requests-oauthlib==1.3.0 in /usr/local/lib/python3.8/dist-packages (from -r requirements.txt (line 112)) (1.3.0)\n",
            "Requirement already satisfied: retworkx==0.8.0 in /usr/local/lib/python3.8/dist-packages (from -r requirements.txt (line 113)) (0.8.0)\n",
            "Requirement already satisfied: rsa==4.7.2 in /usr/local/lib/python3.8/dist-packages (from -r requirements.txt (line 114)) (4.7.2)\n",
            "Requirement already satisfied: scikit-learn==0.24.1 in /usr/local/lib/python3.8/dist-packages (from -r requirements.txt (line 115)) (0.24.1)\n",
            "Requirement already satisfied: scipy==1.6.1 in /usr/local/lib/python3.8/dist-packages (from -r requirements.txt (line 116)) (1.6.1)\n",
            "Requirement already satisfied: semantic-version==2.6.0 in /usr/local/lib/python3.8/dist-packages (from -r requirements.txt (line 117)) (2.6.0)\n",
            "Requirement already satisfied: Send2Trash==1.8.0 in /usr/local/lib/python3.8/dist-packages (from -r requirements.txt (line 118)) (1.8.0)\n",
            "Requirement already satisfied: six==1.15.0 in /usr/local/lib/python3.8/dist-packages (from -r requirements.txt (line 119)) (1.15.0)\n",
            "Requirement already satisfied: sklearn==0.0 in /usr/local/lib/python3.8/dist-packages (from -r requirements.txt (line 120)) (0.0)\n",
            "Requirement already satisfied: soupsieve==2.2.1 in /usr/local/lib/python3.8/dist-packages (from -r requirements.txt (line 121)) (2.2.1)\n",
            "Requirement already satisfied: sympy==1.7.1 in /usr/local/lib/python3.8/dist-packages (from -r requirements.txt (line 122)) (1.7.1)\n",
            "Requirement already satisfied: tensorboard==2.4.1 in /usr/local/lib/python3.8/dist-packages (from -r requirements.txt (line 123)) (2.4.1)\n",
            "Requirement already satisfied: tensorboard-plugin-wit==1.8.0 in /usr/local/lib/python3.8/dist-packages (from -r requirements.txt (line 124)) (1.8.0)\n",
            "Requirement already satisfied: terminado==0.12.1 in /usr/local/lib/python3.8/dist-packages (from -r requirements.txt (line 125)) (0.12.1)\n",
            "Requirement already satisfied: testpath==0.5.0 in /usr/local/lib/python3.8/dist-packages (from -r requirements.txt (line 126)) (0.5.0)\n",
            "Requirement already satisfied: threadpoolctl==2.1.0 in /usr/local/lib/python3.8/dist-packages (from -r requirements.txt (line 127)) (2.1.0)\n",
            "Requirement already satisfied: toml==0.10.2 in /usr/local/lib/python3.8/dist-packages (from -r requirements.txt (line 128)) (0.10.2)\n",
            "Requirement already satisfied: torch==1.8.1 in /usr/local/lib/python3.8/dist-packages (from -r requirements.txt (line 129)) (1.8.1)\n",
            "Requirement already satisfied: torchmetrics==0.2.0 in /usr/local/lib/python3.8/dist-packages (from -r requirements.txt (line 130)) (0.2.0)\n",
            "Requirement already satisfied: torchvision==0.9.1 in /usr/local/lib/python3.8/dist-packages (from -r requirements.txt (line 131)) (0.9.1)\n",
            "Requirement already satisfied: tornado==6.1 in /usr/local/lib/python3.8/dist-packages (from -r requirements.txt (line 132)) (6.1)\n",
            "Requirement already satisfied: tqdm==4.60.0 in /usr/local/lib/python3.8/dist-packages (from -r requirements.txt (line 133)) (4.60.0)\n",
            "Requirement already satisfied: traitlets==5.1.0 in /usr/local/lib/python3.8/dist-packages (from -r requirements.txt (line 134)) (5.1.0)\n",
            "Requirement already satisfied: typing-extensions==3.7.4.3 in /usr/local/lib/python3.8/dist-packages (from -r requirements.txt (line 135)) (3.7.4.3)\n",
            "Requirement already satisfied: urllib3==1.26.4 in /usr/local/lib/python3.8/dist-packages (from -r requirements.txt (line 136)) (1.26.4)\n",
            "Requirement already satisfied: wcwidth==0.2.5 in /usr/local/lib/python3.8/dist-packages (from -r requirements.txt (line 137)) (0.2.5)\n",
            "Requirement already satisfied: webencodings==0.5.1 in /usr/local/lib/python3.8/dist-packages (from -r requirements.txt (line 138)) (0.5.1)\n",
            "Requirement already satisfied: websockets==8.1 in /usr/local/lib/python3.8/dist-packages (from -r requirements.txt (line 139)) (8.1)\n",
            "Requirement already satisfied: Werkzeug==1.0.1 in /usr/local/lib/python3.8/dist-packages (from -r requirements.txt (line 140)) (1.0.1)\n",
            "Requirement already satisfied: widgetsnbextension==3.5.1 in /usr/local/lib/python3.8/dist-packages (from -r requirements.txt (line 141)) (3.5.1)\n",
            "Requirement already satisfied: yarl==1.6.3 in /usr/local/lib/python3.8/dist-packages (from -r requirements.txt (line 142)) (1.6.3)\n",
            "Requirement already satisfied: yfinance==0.1.55 in /usr/local/lib/python3.8/dist-packages (from -r requirements.txt (line 143)) (0.1.55)\n",
            "Requirement already satisfied: setuptools>=40.3.0 in /usr/local/lib/python3.8/dist-packages (from google-auth==1.28.0->-r requirements.txt (line 31)) (57.4.0)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.8/dist-packages (from tensorboard==2.4.1->-r requirements.txt (line 123)) (0.38.4)\n",
            "Installing collected packages: matplotlib\n",
            "  Attempting uninstall: matplotlib\n",
            "    Found existing installation: matplotlib 3.6.2\n",
            "    Uninstalling matplotlib-3.6.2:\n",
            "      Successfully uninstalled matplotlib-3.6.2\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "yellowbrick 1.5 requires scikit-learn>=1.0.0, but you have scikit-learn 0.24.1 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed matplotlib-3.4.1\n"
          ]
        }
      ],
      "source": [
        "!pip install -r requirements.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "iyWlU7b0NI6m"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "\n",
        "#from qlstm_pennylane import QLSTM"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BlxkiVDWNI6n"
      },
      "source": [
        "Here we define the possible tags: determinant, noun, verb."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "qMQSRRStNI6n"
      },
      "outputs": [],
      "source": [
        "tag_to_ix = {\"DET\": 0, \"NN\": 1, \"V\": 2}  # Assign each tag with a unique index\n",
        "ix_to_tag = {i:k for k,i in tag_to_ix.items()}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6y_Q7xc3NI6o"
      },
      "source": [
        "The function below tokenizes the sentence and matches the label to each word."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "UCK__S-DNI6o"
      },
      "outputs": [],
      "source": [
        "def prepare_sequence(seq, to_ix):\n",
        "    idxs = [to_ix[w] for w in seq]\n",
        "    return torch.tensor(idxs, dtype=torch.long)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pc9Vi9-2NI6p"
      },
      "source": [
        "Now we can prepare the input dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "aknP4bmWNI6p",
        "outputId": "d4931425-3d34-42e4-f102-71e382ff16c3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Vocabulary: {'The': 0, 'dog': 1, 'ate': 2, 'the': 3, 'apple': 4, 'Everybody': 5, 'read': 6, 'that': 7, 'book': 8}\n",
            "Entities: {0: 'DET', 1: 'NN', 2: 'V'}\n"
          ]
        }
      ],
      "source": [
        "training_data = [\n",
        "    # Tags are: DET - determiner; NN - noun; V - verb\n",
        "    # For example, the word \"The\" is a determiner\n",
        "    (\"The dog ate the apple\".split(), [\"DET\", \"NN\", \"V\", \"DET\", \"NN\"]),\n",
        "    (\"Everybody read that book\".split(), [\"NN\", \"V\", \"DET\", \"NN\"])\n",
        "]\n",
        "word_to_ix = {}\n",
        "\n",
        "# For each words-list (sentence) and tags-list in each tuple of training_data\n",
        "for sent, tags in training_data:\n",
        "    for word in sent:\n",
        "        if word not in word_to_ix:  # word has not been assigned an index yet\n",
        "            word_to_ix[word] = len(word_to_ix)  # Assign each word with a unique index\n",
        "\n",
        "print(f\"Vocabulary: {word_to_ix}\")\n",
        "print(f\"Entities: {ix_to_tag}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OeXTUjoJNI6q"
      },
      "source": [
        "The idea is to pass the two sequences through the LSTM, which will output the hidden array of vectors [h_0, h_1, h_2, h_3, h_4], one for each word. A dense layer “head” is attached to the LSTM’s outputs to calculate the probability that each word may be a determinant, noun or verb."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "CWbkv_tvNI6q"
      },
      "outputs": [],
      "source": [
        "class LSTMTagger(nn.Module):\n",
        "\n",
        "    def __init__(self, embedding_dim, hidden_dim, vocab_size, tagset_size, n_qubits=0):\n",
        "        super(LSTMTagger, self).__init__()\n",
        "        self.hidden_dim = hidden_dim\n",
        "\n",
        "        self.word_embeddings = nn.Embedding(vocab_size, embedding_dim)\n",
        "\n",
        "        # The LSTM takes word embeddings as inputs, and outputs hidden states\n",
        "        # with dimensionality hidden_dim.\n",
        "        if n_qubits > 0:\n",
        "            print(\"Tagger will use Quantum LSTM\")\n",
        "            self.lstm = QLSTM(embedding_dim, hidden_dim, n_qubits=n_qubits)\n",
        "        else:\n",
        "            print(\"Tagger will use Classical LSTM\")\n",
        "            self.lstm = nn.LSTM(embedding_dim, hidden_dim)\n",
        "\n",
        "        # The linear layer that maps from hidden state space to tag space\n",
        "        self.hidden2tag = nn.Linear(hidden_dim, tagset_size)\n",
        "\n",
        "    def forward(self, sentence):\n",
        "        embeds = self.word_embeddings(sentence)\n",
        "        lstm_out, _ = self.lstm(embeds.view(len(sentence), 1, -1))\n",
        "        tag_logits = self.hidden2tag(lstm_out.view(len(sentence), -1))\n",
        "        tag_scores = F.log_softmax(tag_logits, dim=1)\n",
        "        return tag_scores"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "oGDag6hYNI6q"
      },
      "outputs": [],
      "source": [
        "embedding_dim = 8\n",
        "hidden_dim = 6\n",
        "n_epochs = 300"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "iUAjD2dGNI6r",
        "outputId": "58b0bc05-a02c-458c-d09d-9b3d48d77112",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tagger will use Classical LSTM\n"
          ]
        }
      ],
      "source": [
        "model_classical = LSTMTagger(embedding_dim, \n",
        "                        hidden_dim, \n",
        "                        vocab_size=len(word_to_ix), \n",
        "                        tagset_size=len(tag_to_ix), \n",
        "                        n_qubits=0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M-dwMWyzNI6r"
      },
      "source": [
        "## Training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z5L0dZHfNI6r"
      },
      "source": [
        "Following the example from the PyTorch website, we train the two networks (classical and quantum LSTM) for 300 epochs. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "MII7BdHQNI6s"
      },
      "outputs": [],
      "source": [
        "def train(model, n_epochs):\n",
        "    loss_function = nn.NLLLoss()\n",
        "    optimizer = optim.SGD(model.parameters(), lr=0.1)\n",
        "\n",
        "    history = {\n",
        "        'loss': [],\n",
        "        'acc': []\n",
        "    }\n",
        "    for epoch in range(n_epochs):\n",
        "        losses = []\n",
        "        preds = []\n",
        "        targets = []\n",
        "        for sentence, tags in training_data:\n",
        "            # Step 1. Remember that Pytorch accumulates gradients.\n",
        "            # We need to clear them out before each instance\n",
        "            model.zero_grad()\n",
        "\n",
        "            # Step 2. Get our inputs ready for the network, that is, turn them into\n",
        "            # Tensors of word indices.\n",
        "            sentence_in = prepare_sequence(sentence, word_to_ix)\n",
        "            labels = prepare_sequence(tags, tag_to_ix)\n",
        "\n",
        "            # Step 3. Run our forward pass.\n",
        "            tag_scores = model(sentence_in)\n",
        "\n",
        "            # Step 4. Compute the loss, gradients, and update the parameters by\n",
        "            #  calling optimizer.step()\n",
        "            loss = loss_function(tag_scores, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            losses.append(float(loss))\n",
        "            \n",
        "            probs = torch.softmax(tag_scores, dim=-1)\n",
        "            preds.append(probs.argmax(dim=-1))\n",
        "            targets.append(labels)\n",
        "\n",
        "        avg_loss = np.mean(losses)\n",
        "        history['loss'].append(avg_loss)\n",
        "        \n",
        "        preds = torch.cat(preds)\n",
        "        targets = torch.cat(targets)\n",
        "        corrects = (preds == targets)\n",
        "        accuracy = corrects.sum().float() / float(targets.size(0) )\n",
        "        history['acc'].append(accuracy)\n",
        "\n",
        "        print(f\"Epoch {epoch+1} / {n_epochs}: Loss = {avg_loss:.3f} Acc = {accuracy:.2f}\")\n",
        "\n",
        "    return history"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IMbE2IAFNI6s"
      },
      "outputs": [],
      "source": [
        "history_classical = train(model_classical, n_epochs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "ah4BB1W9NI6t"
      },
      "outputs": [],
      "source": [
        "def print_result(model):\n",
        "    with torch.no_grad():\n",
        "        input_sentence = training_data[0][0]\n",
        "        labels = training_data[0][1]\n",
        "        inputs = prepare_sequence(input_sentence, word_to_ix)\n",
        "        tag_scores = model(inputs)\n",
        "\n",
        "        tag_ids = torch.argmax(tag_scores, dim=1).numpy()\n",
        "        tag_labels = [ix_to_tag[k] for k in tag_ids]\n",
        "        print(f\"Sentence:  {input_sentence}\")\n",
        "        print(f\"Labels:    {labels}\")\n",
        "        print(f\"Predicted: {tag_labels}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "-YT0Lm4dNI6t",
        "outputId": "1293734e-7524-41f4-9baa-a0a669f5bc52",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sentence:  ['The', 'dog', 'ate', 'the', 'apple']\n",
            "Labels:    ['DET', 'NN', 'V', 'DET', 'NN']\n",
            "Predicted: ['DET', 'NN', 'V', 'DET', 'NN']\n"
          ]
        }
      ],
      "source": [
        "print_result(model_classical)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "import pennylane as qml\n",
        "from math import *\n",
        "\n",
        "\n",
        "class QLSTM(nn.Module):\n",
        "    def __init__(self, \n",
        "                input_size, \n",
        "                hidden_size, \n",
        "                n_qubits=4,\n",
        "                n_qlayers=1,\n",
        "                batch_first=True,\n",
        "                return_sequences=False, \n",
        "                return_state=False,\n",
        "                backend=\"default.qubit\"):\n",
        "        super(QLSTM, self).__init__()\n",
        "        self.n_inputs = input_size\n",
        "        self.hidden_size = hidden_size\n",
        "        self.concat_size = self.n_inputs + self.hidden_size\n",
        "        self.n_qubits = n_qubits\n",
        "        self.n_qlayers = n_qlayers\n",
        "        self.backend = backend  # \"default.qubit\", \"qiskit.basicaer\", \"qiskit.ibm\"\n",
        "\n",
        "        self.batch_first = batch_first\n",
        "        self.return_sequences = return_sequences\n",
        "        self.return_state = return_state\n",
        "\n",
        "        #self.dev = qml.device(\"default.qubit\", wires=self.n_qubits)\n",
        "        #self.dev = qml.device('qiskit.basicaer', wires=self.n_qubits)\n",
        "        #self.dev = qml.device('qiskit.ibm', wires=self.n_qubits)\n",
        "        # use 'qiskit.ibmq' instead to run on hardware\n",
        "\n",
        "        self.wires_forget = [f\"wire_forget_{i}\" for i in range(self.n_qubits)]\n",
        "        self.wires_input = [f\"wire_input_{i}\" for i in range(self.n_qubits)]\n",
        "        self.wires_update = [f\"wire_update_{i}\" for i in range(self.n_qubits)]\n",
        "        self.wires_output = [f\"wire_output_{i}\" for i in range(self.n_qubits)]\n",
        "\n",
        "        self.dev_forget = qml.device(self.backend, wires=self.wires_forget)\n",
        "        self.dev_input = qml.device(self.backend, wires=self.wires_input)\n",
        "        self.dev_update = qml.device(self.backend, wires=self.wires_update)\n",
        "        self.dev_output = qml.device(self.backend, wires=self.wires_output)\n",
        "\n",
        "        def _circuit_forget(inputs, weights):\n",
        "            qml.templates.AngleEmbedding(inputs, wires=self.wires_forget)\n",
        "            qml.templates.BasicEntanglerLayers(weights, wires=self.wires_forget)\n",
        "            return [qml.expval(qml.PauliZ(wires=w)) for w in self.wires_forget]\n",
        "        self.qlayer_forget = qml.QNode(_circuit_forget, self.dev_forget, interface=\"torch\")\n",
        "\n",
        "        def _circuit_input(inputs, weights):\n",
        "            qml.templates.AngleEmbedding(inputs, wires=self.wires_input)\n",
        "            qml.templates.BasicEntanglerLayers(weights, wires=self.wires_input, rotation=qml.RY)\n",
        "            qml.templates.BasicEntanglerLayers(weights, wires=self.wires_input, rotation=qml.RZ)\n",
        "            return [qml.expval(qml.PauliZ(wires=w)) for w in self.wires_input]\n",
        "        self.qlayer_input = qml.QNode(_circuit_input, self.dev_input, interface=\"torch\")\n",
        "\n",
        "        def _circuit_update(inputs, weights):\n",
        "            qml.templates.AngleEmbedding(inputs, wires=self.wires_update)\n",
        "            qml.templates.BasicEntanglerLayers(weights, wires=self.wires_update)\n",
        "            return [qml.expval(qml.PauliZ(wires=w)) for w in self.wires_update]\n",
        "        self.qlayer_update = qml.QNode(_circuit_update, self.dev_update, interface=\"torch\")\n",
        "\n",
        "        def _circuit_output(inputs, weights):\n",
        "            qml.templates.AngleEmbedding(inputs, wires=self.wires_output)\n",
        "            qml.templates.BasicEntanglerLayers(weights, wires=self.wires_output)\n",
        "            return [qml.expval(qml.PauliZ(wires=w)) for w in self.wires_output]\n",
        "        self.qlayer_output = qml.QNode(_circuit_output, self.dev_output, interface=\"torch\")\n",
        "\n",
        "        weight_shapes = {\"weights\": (n_qlayers, n_qubits)}\n",
        "        print(f\"weight_shapes = (n_qlayers, n_qubits) = ({n_qlayers}, {n_qubits})\")\n",
        "\n",
        "        self.clayer_in = torch.nn.Linear(self.concat_size, n_qubits)\n",
        "        self.VQC = {\n",
        "            'forget': qml.qnn.TorchLayer(self.qlayer_forget, weight_shapes),\n",
        "            'input': qml.qnn.TorchLayer(self.qlayer_input, weight_shapes),\n",
        "            'update': qml.qnn.TorchLayer(self.qlayer_update, weight_shapes),\n",
        "            'output': qml.qnn.TorchLayer(self.qlayer_output, weight_shapes)\n",
        "        }\n",
        "        self.clayer_out = torch.nn.Linear(self.n_qubits, self.hidden_size)\n",
        "        #self.clayer_out = [torch.nn.Linear(n_qubits, self.hidden_size) for _ in range(4)]\n",
        "\n",
        "    def forward(self, x, init_states=None):\n",
        "        '''\n",
        "        x.shape is (batch_size, seq_length, feature_size)\n",
        "        recurrent_activation -> sigmoid\n",
        "        activation -> tanh\n",
        "        '''\n",
        "        if self.batch_first is True:\n",
        "            batch_size, seq_length, features_size = x.size()\n",
        "        else:\n",
        "            seq_length, batch_size, features_size = x.size()\n",
        "\n",
        "        hidden_seq = []\n",
        "        if init_states is None:\n",
        "            h_t = torch.zeros(batch_size, self.hidden_size)  # hidden state (output)\n",
        "            c_t = torch.zeros(batch_size, self.hidden_size)  # cell state\n",
        "        else:\n",
        "            # for now we ignore the fact that in PyTorch you can stack multiple RNNs\n",
        "            # so we take only the first elements of the init_states tuple init_states[0][0], init_states[1][0]\n",
        "            h_t, c_t = init_states\n",
        "            h_t = h_t[0]\n",
        "            c_t = c_t[0]\n",
        "\n",
        "        for t in range(seq_length):\n",
        "            # get features from the t-th element in seq, for all entries in the batch\n",
        "            x_t = x[:, t, :]\n",
        "            \n",
        "            # Concatenate input and hidden state\n",
        "            v_t = torch.cat((h_t, x_t), dim=1)\n",
        "\n",
        "            # match qubit dimension\n",
        "            y_t = self.clayer_in(v_t)\n",
        "\n",
        "            f_t = torch.sigmoid(self.clayer_out(self.VQC['forget'](y_t)))  # forget block\n",
        "            i_t = torch.sigmoid(self.clayer_out(self.VQC['input'](y_t)))  # input block\n",
        "            g_t = torch.tanh(self.clayer_out(self.VQC['update'](y_t)))  # update block\n",
        "            o_t = torch.sigmoid(self.clayer_out(self.VQC['output'](y_t))) # output block\n",
        "\n",
        "            c_t = (f_t * c_t) + (i_t * g_t)\n",
        "            h_t = o_t * torch.tanh(c_t)\n",
        "\n",
        "            hidden_seq.append(h_t.unsqueeze(0))\n",
        "        hidden_seq = torch.cat(hidden_seq, dim=0)\n",
        "        hidden_seq = hidden_seq.transpose(0, 1).contiguous()\n",
        "        return hidden_seq, (h_t, c_t)"
      ],
      "metadata": {
        "id": "7umGth29OXFp"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "dUVMYFFJNI6t",
        "outputId": "7c18c1b8-b12e-48b9-c39f-bad86e136275",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tagger will use Quantum LSTM\n",
            "weight_shapes = (n_qlayers, n_qubits) = (1, 4)\n"
          ]
        }
      ],
      "source": [
        "n_qubits = 4\n",
        "\n",
        "model_quantum = LSTMTagger(embedding_dim, \n",
        "                        hidden_dim, \n",
        "                        vocab_size=len(word_to_ix), \n",
        "                        tagset_size=len(tag_to_ix), \n",
        "                        n_qubits=n_qubits)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IjF9NvReNI6u"
      },
      "outputs": [],
      "source": [
        "history_quantum = train(model_quantum, n_epochs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "WvPWB2jHNI6u",
        "outputId": "e14dcc41-a5b0-4387-d0f5-23f744d99bf7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sentence:  ['The', 'dog', 'ate', 'the', 'apple']\n",
            "Labels:    ['DET', 'NN', 'V', 'DET', 'NN']\n",
            "Predicted: ['DET', 'NN', 'V', 'DET', 'NN']\n"
          ]
        }
      ],
      "source": [
        "print_result(model_quantum)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U matplotlib"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i3hBZuLQULw3",
        "outputId": "f91b41ad-cb78-481b-d346-fccfba0b4bf8"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.8/dist-packages (3.4.1)\n",
            "Collecting matplotlib\n",
            "  Downloading matplotlib-3.6.2-cp38-cp38-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (9.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.4/9.4 MB\u001b[0m \u001b[31m50.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.8/dist-packages (from matplotlib) (0.10.0)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.8/dist-packages (from matplotlib) (8.2.0)\n",
            "Requirement already satisfied: numpy>=1.19 in /usr/local/lib/python3.8/dist-packages (from matplotlib) (1.20.1)\n",
            "Requirement already satisfied: pyparsing>=2.2.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib) (2.4.7)\n",
            "Collecting contourpy>=1.0.1\n",
            "  Downloading contourpy-1.0.6-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (295 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m296.0/296.0 KB\u001b[0m \u001b[31m29.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.8/dist-packages (from matplotlib) (2.8.1)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.8/dist-packages (from matplotlib) (21.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib) (1.3.1)\n",
            "Collecting fonttools>=4.22.0\n",
            "  Downloading fonttools-4.38.0-py3-none-any.whl (965 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m965.4/965.4 KB\u001b[0m \u001b[31m70.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.8/dist-packages (from cycler>=0.10->matplotlib) (1.15.0)\n",
            "Installing collected packages: fonttools, contourpy, matplotlib\n",
            "  Attempting uninstall: matplotlib\n",
            "    Found existing installation: matplotlib 3.4.1\n",
            "    Uninstalling matplotlib-3.4.1:\n",
            "      Successfully uninstalled matplotlib-3.4.1\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "yellowbrick 1.5 requires scikit-learn>=1.0.0, but you have scikit-learn 0.24.1 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed contourpy-1.0.6 fonttools-4.38.0 matplotlib-3.6.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qVuTwIpINI6v"
      },
      "source": [
        "### Plot the training history"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "id": "27Ba0B8HNI6v"
      },
      "outputs": [],
      "source": [
        "from matplotlib import pyplot as plt\n",
        "\n",
        "def plot_history(history_classical, history_quantum):\n",
        "    loss_c = history_classical['loss']\n",
        "    acc_c = history_classical['acc']\n",
        "    loss_q = history_quantum['loss']\n",
        "    acc_q = history_quantum['acc']\n",
        "    n_epochs = max([len(loss_c), len(loss_q)])\n",
        "    x_epochs = [i for i in range(n_epochs)]\n",
        "    \n",
        "    fig, ax1 = plt.subplots()\n",
        "    \n",
        "    ax1.set_xlabel(\"Epoch\")\n",
        "    ax1.set_ylabel(\"Loss\")\n",
        "    ax1.plot(loss_c, label=\"Classical LSTM loss\", color='orange', linestyle='dashed')\n",
        "    ax1.plot(loss_q, label=\"Quantum LSTM loss\", color='red', linestyle='solid')\n",
        "\n",
        "    ax2 = ax1.twinx()\n",
        "    ax2.set_ylabel(\"Accuracy\")\n",
        "    ax2.plot(acc_c, label=\"Classical LSTM accuracy\", color='steelblue', linestyle='dashed')\n",
        "    ax2.plot(acc_q, label=\"Quantum LSTM accuracy\", color='blue', linestyle='solid')\n",
        "\n",
        "    plt.title(\"Part-of-Speech Tagger Training\")\n",
        "    plt.ylim(0., 1.1)\n",
        "    #plt.legend(loc=\"upper right\")\n",
        "    fig.legend(loc=\"upper right\", bbox_to_anchor=(1,0.8), bbox_transform=ax1.transAxes)\n",
        "\n",
        "    #plt.savefig(\"pos_training.pdf\")\n",
        "    #plt.savefig(\"pos_training.png\")\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {
        "id": "rZVXO_T7NI6v",
        "outputId": "1aa71a75-c374-4b91-ddf9-09329b47df25",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 395
        }
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "ImportError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/IPython/core/formatters.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    339\u001b[0m                 \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    340\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 341\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mprinter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    342\u001b[0m             \u001b[0;31m# Finally look for special method names\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    343\u001b[0m             \u001b[0mmethod\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_real_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprint_method\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/IPython/core/pylabtools.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(fig)\u001b[0m\n\u001b[1;32m    242\u001b[0m         \u001b[0mformatter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mshell\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdisplay_formatter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mipython_display_formatter\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    243\u001b[0m         \u001b[0mformatter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfor_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mFigure\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_reshow_nbagg_figure\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 244\u001b[0;31m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    245\u001b[0m     \u001b[0msupported\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'png'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'png2x'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'retina'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'jpg'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'jpeg'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'svg'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'pdf'\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    246\u001b[0m     \u001b[0mbad\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mformats\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdifference\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msupported\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/IPython/core/pylabtools.py\u001b[0m in \u001b[0;36mprint_figure\u001b[0;34m(fig, fmt, bbox_inches, **kwargs)\u001b[0m\n\u001b[1;32m    126\u001b[0m         \u001b[0;34m\"dpi\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mdpi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m         \u001b[0;34m\"bbox_inches\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mbbox_inches\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 128\u001b[0;31m     }\n\u001b[0m\u001b[1;32m    129\u001b[0m     \u001b[0;31m# **kwargs get higher priority\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m     \u001b[0mkw\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/matplotlib/backend_bases.py\u001b[0m in \u001b[0;36mprint_figure\u001b[0;34m(self, filename, dpi, facecolor, edgecolor, orientation, format, bbox_inches, **kwargs)\u001b[0m\n\u001b[1;32m   2089\u001b[0m         \u001b[0mbackend\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2090\u001b[0m             \u001b[0mIf\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mswitch\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mfigure\u001b[0m \u001b[0mcanvas\u001b[0m \u001b[0mto\u001b[0m \u001b[0mthe\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mFigureCanvas\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0;32mclass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2091\u001b[0;31m             \u001b[0mof\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mgiven\u001b[0m \u001b[0mbackend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2092\u001b[0m         \u001b[0mfmt\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2093\u001b[0m             \u001b[0mIf\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mbackend\u001b[0m\u001b[0;34m*\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mthen\u001b[0m \u001b[0mdetermine\u001b[0m \u001b[0ma\u001b[0m \u001b[0msuitable\u001b[0m \u001b[0mcanvas\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0;32mfor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/matplotlib/backend_bases.py\u001b[0m in \u001b[0;36m_get_renderer\u001b[0;34m(figure, print_method)\u001b[0m\n\u001b[1;32m   1558\u001b[0m     \"\"\"\n\u001b[1;32m   1559\u001b[0m     \u001b[0;31m# This is implemented by triggering a draw, then immediately jumping out of\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1560\u001b[0;31m     \u001b[0;31m# Figure.draw() by raising an exception.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1561\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1562\u001b[0m     \u001b[0;32mclass\u001b[0m \u001b[0mDone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mException\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/matplotlib/backends/backend_agg.py\u001b[0m in \u001b[0;36mprint_png\u001b[0;34m(self, filename_or_obj, metadata, pil_kwargs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    503\u001b[0m             \u001b[0mKeyword\u001b[0m \u001b[0marguments\u001b[0m \u001b[0mpassed\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mPIL\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    504\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 505\u001b[0;31m             \u001b[0mIf\u001b[0m \u001b[0mthe\u001b[0m \u001b[0;34m'pnginfo'\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mpresent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mit\u001b[0m \u001b[0mcompletely\u001b[0m \u001b[0moverrides\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    506\u001b[0m             \u001b[0;34m*\u001b[0m\u001b[0mmetadata\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mincluding\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mdefault\u001b[0m \u001b[0;34m'Software'\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    507\u001b[0m         \"\"\"\n",
            "\u001b[0;31mImportError\u001b[0m: cannot import name '_png' from 'matplotlib' (/usr/local/lib/python3.8/dist-packages/matplotlib/__init__.py)"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "plot_history(history_classical, history_quantum)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y9s90KDYNI6w"
      },
      "source": [
        "The loss function decreases as a function of the training epoch, and after 300 epochs both networks are able to tag correctly the first sentence. Due to the complexity of the simulation of the quantum circuit, it took approximatively 15 minutes to finish the training, to be compared to a mere 8 seconds for the classical case. "
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.9"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}